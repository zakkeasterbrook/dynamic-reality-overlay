<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Precise Object Detector with Alignment Correction</title>
    <!-- Include TensorFlow.js and MobileNet-SSD model -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background: linear-gradient(45deg, #0f0f0f, #1e1e1e);
            color: #fff;
            font-family: Arial, sans-serif;
        }
        #camera {
            width: 100vw;
            height: 100vh;
            object-fit: cover;
            position: absolute;
            z-index: 1;
        }
        #visual-feedback {
            position: absolute;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            pointer-events: none;
            z-index: 2;
        }
        #output {
            font-size: 24px;
            font-weight: bold;
            text-shadow: 0 0 5px #000;
            margin-top: 10px;
            z-index: 3;
            position: absolute;
            top: 10px;
            left: 10px;
        }
        #error-log {
            color: #f66;
            font-size: 14px;
            margin-top: 10px;
            z-index: 3;
            position: absolute;
            top: 50px;
            left: 10px;
        }
        #controls {
            position: fixed;
            bottom: 20px;
            display: flex;
            justify-content: center;
            gap: 20px;
            z-index: 4;
        }
        .button {
            padding: 10px 25px;
            font-size: 16px;
            background: #28a745;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background 0.3s, transform 0.3s;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
        }
        .button:hover {
            background: #218838;
            transform: translateY(-2px);
        }
        .button:active {
            background: #1e7e34;
            transform: translateY(1px);
        }
    </style>
</head>
<body>
    <video id="camera" autoplay playsinline></video>
    <canvas id="visual-feedback"></canvas>
    <div id="output">Objects detected: --</div>
    <div id="error-log"></div>

    <div id="controls">
        <button class="button" onclick="resetTracking()">Reset Tracking</button>
        <button class="button" onclick="toggleBoundingBox()">Toggle Bounding Box</button>
        <button class="button" onclick="adjustSensitivity()">Adjust Sensitivity</button>
    </div>

    <script>
        const video = document.getElementById('camera');
        const canvas = document.getElementById('visual-feedback');
        const context = canvas.getContext('2d');
        const output = document.getElementById('output');
        const errorLog = document.getElementById('error-log');
        let model;
        let showBoundingBox = true;
        const verticalOffset = 10; // Adjust this value to bring the bounding boxes down

        // Load the MobileNet-SSD model
        async function loadModel() {
            try {
                model = await cocoSsd.load();
                logError("Model loaded successfully.");
                startCamera();
            } catch (error) {
                logError(`Error loading model: ${error.message}`);
            }
        }

        // Start camera
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: { ideal: 'environment' }, frameRate: { ideal: 30, max: 60 } }
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    adjustCanvasSize();
                    detectObjects();
                };
                window.addEventListener('resize', adjustCanvasSize);
            } catch (error) {
                logError(`Error accessing the camera: ${error.message}. Please check camera permissions or try a different device.`);
            }
        }

        // Adjust canvas size to match video dimensions
        function adjustCanvasSize() {
            const aspectRatio = video.videoWidth / video.videoHeight;
            const windowAspectRatio = window.innerWidth / window.innerHeight;
            if (aspectRatio > windowAspectRatio) {
                // Video is wider than window
                video.style.width = '100vw';
                video.style.height = 'auto';
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight * (window.innerWidth / video.videoWidth);
            } else {
                // Video is taller than window
                video.style.height = '100vh';
                video.style.width = 'auto';
                canvas.width = video.videoWidth * (window.innerHeight / video.videoHeight);
                canvas.height = video.videoHeight;
            }
            canvas.style.width = video.style.width;
            canvas.style.height = video.style.height;
        }

        // Detect objects using the MobileNet-SSD model
        async function detectObjects() {
            try {
                const predictions = await model.detect(video);
                context.clearRect(0, 0, canvas.width, canvas.height);
                drawResults(predictions);
                requestAnimationFrame(detectObjects);
            } catch (error) {
                logError(`Error during detection: ${error.message}`);
            }
        }

        // Draw detection results
        function drawResults(predictions) {
            const scaleX = canvas.width / video.videoWidth;
            const scaleY = canvas.height / video.videoHeight;
            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox.map((value, index) => 
                    index % 2 === 0 ? value * scaleX : value * scaleY
                );
                context.strokeStyle = 'cyan';
                context.lineWidth = 2;
                context.strokeRect(x, y + verticalOffset, width, height);
                context.fillStyle = 'cyan';
                context.font = '16px Arial';
                context.fillText(
                    `${prediction.class} - ${Math.round(prediction.score * 100)}%`,
                    x,
                    y > 10 ? y - 5 : 10
                );
            });
            output.textContent = `Objects detected: ${predictions.length}`;
        }

        // Log errors
        function logError(message) {
            errorLog.textContent += `${message}\n`;
            console.error(message);
        }

        // Reset tracking data
        function resetTracking() {
            output.textContent = "Objects detected: --";
            logError("Tracking reset.");
        }

        // Toggle the bounding box visibility
        function toggleBoundingBox() {
            showBoundingBox = !showBoundingBox;
            logError(`Bounding box ${showBoundingBox ? 'enabled' : 'disabled'}.`);
        }

        // Adjust sensitivity of detection
        function adjustSensitivity() {
            const newThreshold = prompt("Set detection threshold (default 0.5):", 0.5);
            logError(`Detection threshold adjusted to ${newThreshold}.`);
        }

        // Load model and start the application
        loadModel();
    </script>
</body>
</html>
