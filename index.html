<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultimate Golf Club Head Tracker</title>
    <!-- Include TensorFlow.js and necessary models -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background: linear-gradient(45deg, #0f0f0f, #1e1e1e);
            color: #fff;
            font-family: Arial, sans-serif;
        }
        #camera {
            width: 100%;
            height: 70%;
            object-fit: cover;
            border: 2px solid #444;
            border-radius: 10px;
            position: relative;
            z-index: 1;
        }
        #visual-feedback {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 70%;
            pointer-events: none;
            z-index: 2;
        }
        #output {
            font-size: 28px;
            font-weight: bold;
            text-shadow: 0 0 5px #000;
            margin-top: 10px;
            z-index: 3;
        }
        #error-log {
            color: #f66;
            font-size: 14px;
            margin-top: 10px;
            z-index: 3;
        }
        #controls {
            position: fixed;
            bottom: 20px;
            display: flex;
            justify-content: center;
            gap: 20px;
            z-index: 4;
        }
        .button {
            padding: 10px 25px;
            font-size: 18px;
            background: #28a745;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background 0.3s, transform 0.3s;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
        }
        .button:hover {
            background: #218838;
            transform: translateY(-2px);
        }
        .button:active {
            background: #1e7e34;
            transform: translateY(1px);
        }
    </style>
</head>
<body>
    <video id="camera" autoplay playsinline></video>
    <canvas id="visual-feedback"></canvas>
    <div id="output">Swing Speed: -- mph</div>
    <div id="error-log"></div>

    <div id="controls">
        <button class="button" onclick="resetTracking()">Reset Tracking</button>
        <button class="button" onclick="toggleBoundingBox()">Toggle Bounding Box</button>
        <button class="button" onclick="adjustSensitivity()">Adjust Sensitivity</button>
    </div>

    <script>
        const video = document.getElementById('camera');
        const canvas = document.getElementById('visual-feedback');
        const context = canvas.getContext('2d');
        const output = document.getElementById('output');
        const errorLog = document.getElementById('error-log');

        // Variables for tracking
        let motionThreshold = 200; // Adjust threshold for detecting significant motion
        let showBoundingBox = true;
        let objectModel, poseModel;

        // Load models
        async function loadModels() {
            [objectModel, poseModel] = await Promise.all([cocoSsd.load(), posenet.load()]);
            logError("Models loaded successfully.");
            startCamera();
        }

        // Start camera
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: { ideal: 'environment' }, frameRate: { ideal: 60, max: 120 } } 
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    detectObjectsAndPoses();
                };
            } catch (error) {
                logError(`Error accessing the camera: ${error.message}. Please check camera permissions or try a different device.`);
            }
        }

        // Detect objects and poses in the video frame
        async function detectObjectsAndPoses() {
            const [predictions, poses] = await Promise.all([
                objectModel.detect(video),
                poseModel.estimateSinglePose(video, {
                    flipHorizontal: false,
                    decodingMethod: 'single-person'
                })
            ]);
            context.clearRect(0, 0, canvas.width, canvas.height);
            predictions.forEach(prediction => {
                // Draw all detected objects and label them
                drawBoundingBox(prediction);
            });
            drawPoses(poses);
            requestAnimationFrame(detectObjectsAndPoses);
        }

        // Draw bounding box around detected objects
        function drawBoundingBox(prediction) {
            const scaleX = canvas.width / video.videoWidth;
            const scaleY = canvas.height / video.videoHeight;
            const x = prediction.bbox[0] * scaleX;
            const y = prediction.bbox[1] * scaleY;
            const width = prediction.bbox[2] * scaleX;
            const height = prediction.bbox[3] * scaleY;

            context.strokeStyle = 'cyan';
            context.lineWidth = 3;
            context.beginPath();
            context.rect(x, y, width, height);
            context.stroke();
            context.fillStyle = 'cyan';
            context.font = '16px Arial';
            context.fillText(
                `${prediction.class} - ${Math.round(prediction.score * 100)}%`,
                x,
                y > 10 ? y - 5 : 10
            );
        }

        // Draw poses detected by PoseNet
        function drawPoses(pose) {
            if (pose && pose.keypoints) {
                context.fillStyle = 'yellow';
                context.strokeStyle = 'yellow';
                context.lineWidth = 2;

                // Draw keypoints
                pose.keypoints.forEach(keypoint => {
                    if (keypoint.score > 0.5) { // Draw only if the confidence score is high enough
                        context.beginPath();
                        context.arc(keypoint.position.x, keypoint.position.y, 5, 0, 2 * Math.PI);
                        context.fill();
                    }
                });

                // Draw skeleton
                const adjacentKeyPoints = posenet.getAdjacentKeyPoints(pose.keypoints, 0.5);
                adjacentKeyPoints.forEach(([from, to]) => {
                    context.beginPath();
                    context.moveTo(from.position.x, from.position.y);
                    context.lineTo(to.position.x, to.position.y);
                    context.stroke();
                });
            }
        }

        // Log errors
        function logError(message) {
            errorLog.textContent += `${message}\n`;
            console.error(message);
        }

        // Reset tracking data
        function resetTracking() {
            output.textContent = "Swing Speed: -- mph";
            logError("Tracking reset.");
        }

        // Toggle the bounding box visibility
        function toggleBoundingBox() {
            showBoundingBox = !showBoundingBox;
            logError(`Bounding box ${showBoundingBox ? 'enabled' : 'disabled'}.`);
        }

        // Adjust sensitivity of motion detection
        function adjustSensitivity() {
            motionThreshold = prompt("Set motion sensitivity (default 200):", motionThreshold) || motionThreshold;
            logError(`Motion sensitivity adjusted to ${motionThreshold}.`);
        }

        // Load models and start application
        loadModels();
    </script>
</body>
</html>
